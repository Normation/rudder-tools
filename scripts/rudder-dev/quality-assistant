#!/usr/bin/env python3
# coding: utf8

"""
Pull-request quality tool.

You need a configuration file, if you don't have one, the tool will create one for you at first run.

Usage:
        quality-assistant -h|--help
        quality-assistant merge all [--job-id=<id>] [--work-dir=<directory>] [--alt-dir] [-d|--debug] [-f|--force]
        quality-assistant merge <repo> [--job-id=<id>] [--work-dir=<directory>] [--alt-dir] [-d|--debug] [-f|--force]
        quality-assistant autolabel all [-d|--debug] [-f|--force]
        quality-assistant autolabel <repo> [-d|--debug] [-f|--force]
        quality-assistant pr-cleanup all [-d|--debug] [-f|--force]
        quality-assistant pr-cleanup <repo> [-d|--debug] [-f|--force]

Options:
        alt-dir : after waiting on a lock, use alternate directory instead of failing

        merge <repo>: merge all PR that are tagged "Ready for merge" for theis repo

        merge all: do a merge on all known repositories

        autolabel <repo>: create mandatory labels on github for this repo

        autolabel all: create labels on github for all known repositories

"""

import os
import shutil
import time
import fcntl
import random
from datetime import datetime
from dateutil.parser import parse
from common import *
from github import *
from redmine import *
from tempfile import *

import docopt # apt-get install python-docopt || pip install docopt
from pprint import pprint

try:
  import urllib3
  urllib3.disable_warnings()
except:
  pass

try:
  requests.packages.urllib3.disable_warnings()
except:
  pass

def rudder_dev_cmd():
  if Config.LOGLEVEL == "debug":
    return "rudder-dev --debug"
  return "rudder-dev"

def clean_repo(repo, alt_dir):
  redirect = ""
  if Config.LOGLEVEL == "error":
    redirect = " >/dev/null"

  # check master directory
  workdir = Config.WORKING_DIRECTORY
  if not os.path.isdir(workdir):
    logfail("Master directory doesn't exist, exiting")
    exit(1)

  # check working directory
  directory = workdir + "/" + repo
  if not os.path.isdir(directory):
    os.chdir(workdir)
    shell(rudder_dev_cmd() + " clone "+repo+redirect, "Cloning "+repo+" in the master directory")

  # check lock
  lockfile = directory + "/qa.lock"
  wait = Config.LOCK_TIMEOUT
  fd = open(lockfile, 'w')
  while wait > 0:
    try:
      fcntl.flock(fd,fcntl.LOCK_EX | fcntl.LOCK_NB)
      break
    except:
      print("Lock present, remaining wait time : " + str(wait) + "s")
      w = min(wait,5) # recheck lock every 5s
      time.sleep(w)
      wait -= 5
  try:
    fcntl.flock(fd,fcntl.LOCK_EX | fcntl.LOCK_NB)
  except:
    if alt_dir:
      # since working directory is just a cache to speedup git, we can just create another one if needed
      workdir = mkdtemp()
      directory = workdir + "/" + repo
      lockfile = directory + "/qa.lock"
      os.chdir(workdir)
      shell(rudder_dev_cmd() + " clone "+repo+redirect, "Cloning "+repo+" in a temporary directory")
    else:
      print("Lockfile " + lockfile + " is present, stoping")
      exit(1)

  # cleanup working directory
  os.chdir(directory)
  shell("git clean -f -d -e qa.lock"+redirect, "Cleanup working directory")
  shell("git reset --hard"+redirect, "Reset working directory")

  # make sure removal next line never fails
  shell("git checkout -b tmp 2>/dev/null || git checkout tmp")
  # remove potential destination branches is case they are dirty
  shell("git branch --list 'branches*' --list master --format='%(refname:lstrip=2)' | xargs -r -n1 git branch -D")
  return workdir


def list_repositories():
  repositories = get_config("repos", "No 'repositories' list in " + Config.CONFIG_FILE, section)
  Config.REPOSITORIES = re.split(r'[ ,]+', repositories)


def repo_merge(repo, alt_dir, jobid):
  # Always merge PR with the label "Ready for merge"
  api_url = "https://api.github.com/repos/Normation/{repo}/issues?labels="+Config.PR_VALIDATED_LABEL
  url = api_url.format(repo=repo)
  data = github_call(url)
  for pr_info in data:
    labels = [l['name'] for l in pr_info['labels']]
    if Config.BOT_CANNOT_MERGE_LABEL in labels and not Config.force:
      if Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
        print("Skipping " + pr_info['html_url'] + " : marked as can't merge")
      continue
    pr_merge(repo, pr_info['html_url'], alt_dir, jobid)

  # Merge approved PR only if we are not in freeze period
  freeze = False
  server = Redmine(False)
  if server.has_locked_version('rudder'):
    if Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
      print("Freeze period, approved PR won't be merged !")
    freeze = True

  # List approved PR
  api_url = "https://api.github.com/repos/Normation/{repo}/issues?state=open"
  url = api_url.format(repo=repo)
  data = github_call(url)
  for pr_info in data:
    labels = [l['name'] for l in pr_info['labels']]
    if Config.BOT_CANNOT_MERGE_LABEL in labels and not Config.force:
      if Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
        print("Skipping " + pr_info['html_url'] + " : marked as can't merge")
      continue
    pr = PR(pr_info['html_url'])
    approved = pr.review_approval()
    if approved is None:
      continue
    tested = pr.tests_passed()
    if not tested:
      continue
    # Reassign if a change is requested
    if not approved:
      if Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
        print("Reassigning unapproved PR: " + pr_info['html_url'])
      reassign(pr)
    # Merge approved PR outside of freeze period
    elif not freeze:
      if Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
        print("Merging approved PR: " + pr_info['html_url'])
      pr_merge(repo, pr_info['html_url'], alt_dir, jobid)
    elif Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
      print("We are in freeze period, skipping PR: " + pr_info['html_url'])


def reassign(pr):
  for title in  pr.commits_titles():
    # find issue matching PR title
    match=re.match(r'^Fixes #(\d+)', title)
    if match:
      issue_id = match.group(1)
      issue = Issue(issue_id)
      uid = -1
      # find user matching the author in redmine
      for user in issue.server.list_nrm_users():
        if "custom_fields" in user:
          for field in user["custom_fields"]:
            if field["name"] == "GitHub":
              if "value" in field:
                if field["value"] == pr.author():
                  uid = user ["id"]
      if uid != -1:
        if issue['assigned_to_id'] != uid:
          if Config.LOGLEVEL == "debug":
            print("Found previous owner, reassigning " + pr.url + " to redmine user " + str(uid))
        return
 
def kant_merge():
  quotes = [
          "Science is organized knowledge. Wisdom is organized life.",
          "Two things awe me most, the starry sky above me and the moral law within me.",
          "Thoughts without content are empty, intuitions without concepts are blind.",
          "It is beyond a doubt that all our knowledge begins with experience.",
          "Live your life as though your every act were to become a universal law.",
          "In law a man is guilty when he violates the rights of others. In ethics he is guilty if he only thinks of doing so.",
          "Happiness is not an ideal of reason, but of imagination.",
          "Morality is not the doctrine of how we may make ourselves happy, but how we may make ourselves worthy of happiness.",
          "To be is to do.",
          "All our knowledge begins with the senses, proceeds then to the understanding, and ends with reason. There is nothing higher than reason.",
          ]
  i = random.randint(0,len(quotes)-1)
  return "Kant merge: \"" + quotes[i] + "\"\n"

def pr_merge(repo, url, alt_dir, jobid):
  redirect = ""
  if Config.LOGLEVEL == "debug" or Config.LOGLEVEL == "info":
    print("Merging " + url)
  if Config.LOGLEVEL == "info" or Config.LOGLEVEL == "error":
    redirect = " > /dev/null 2>/dev/null"
  workdir = clean_repo(repo, alt_dir)
  pr = PR(url)
  command = rudder_dev_cmd() + " merge " + url + " --automatic"
  (code, output, stderr) = shell(command + " --test", "Trying to merge PR " + url, fail_exit=False, keep_output=True, keep_error=True)
  log = "-- stdout -- \n" + output + "\n-- stderr --\n" + stderr
  if not (Config.LOGLEVEL == "info" or Config.LOGLEVEL == "error"):
    print(log)
  if code == 127:
    # extract 15 first lines of (error then output) to limit comment size
    lines = (log).split('\n')
    msg = "\n" . join(lines[:5]) + "\n[...]\n" + "\n".join(lines[-10:]) 
    comment="""This PR breaks """ + Config.QA_TEST + """
```
""" + msg + """
```
You should run ./""" + Config.QA_TEST + """ in your repository to make sure it works.
You can also run `rudder-dev merge """ + url + """ --test` to test with upmerging.
After this, you can remove the """ + Config.BOT_CANNOT_MERGE_LABEL + """ ta
-- Your faithful QA"""
    if jobid is not None:
      comment += " (" + str(jobid) + ")"
    pr.comment(comment)
    pr.unlabel(Config.PR_VALIDATED_LABEL)
    pr.label(Config.BOT_CANNOT_MERGE_LABEL)
    reassign(pr)
  elif code != 0:
    # PR must be manually merged
    comment="""This PR is not mergeable to upper versions.
Since it is "Ready for merge" you must merge it by yourself using the following command:
`rudder-dev merge """ + url + """`
-- Your faithful QA
""" + kant_merge()
    if jobid is not None:
      comment += " (" + str(jobid) + ")"
    pr.comment(comment)
    pr.label(Config.BOT_CANNOT_MERGE_LABEL)
    reassign(pr)
  else:
    # PR can be automatically merged
    shell(command + redirect, "Automatically merging PR " + url)

  if workdir != Config.WORKING_DIRECTORY:
    # remove everything temporary
    shutil.rmtree(workdir)


def repo_merge_all(alt_dir, jobid):
  for repo in Config.REPOSITORIES:
    if Config.LOGLEVEL == "debug":
      print("Calling merge on " + repo)
    repo_merge(repo, alt_dir, jobid)


def manage_label(repo, name, color):
  get_url = "https://api.github.com/repos/Normation/{repo}/labels/{name}".format(repo=repo, name=name)
  label = github_call(get_url, fail_ok=True)
  if label is None:
    # no such label, create it
    create_url = "https://api.github.com/repos/Normation/{repo}/labels".format(repo=repo)
    data = '{"name": "' + name + '", "color": "' + color + '" }'
    print("- Creating label: " + name)
    github_call(create_url, post_data=data)
  else:
    # check label color
    if label['color'] != color:
      data = '{"name": "' + name + '", "color": "' + color + '" }'
      print("- Updating color of label: " + name)
      github_call(get_url, post_data=data, method="PATCH")


def autolabel(repo):
  manage_label(repo, Config.BOT_CANNOT_MERGE_LABEL, Config.BOT_CANNOT_MERGE_COLOR)
  manage_label(repo, Config.PR_VALIDATED_LABEL, Config.PR_VALIDATED_COLOR)
  manage_label(repo, Config.PR_TOO_OLD_LABEL, Config.PR_TOO_OLD_COLOR)


def autolabel_all():
  for repo in Config.REPOSITORIES:
    autolabel(repo)


def pr_cleanup(repo):
  url = "https://api.github.com/repos/Normation/{repo}/pulls".format(repo=repo)
  pulls = github_call(url)
  for pull in pulls:
    if pull['state'] != "open":
      continue
    # generic PR info
    updated = parse(pull['updated_at'], ignoretz=True)
    author = pull['user']['login']
    pr = PR(pull['html_url'])
    mergeable = pr.mergeable()
    unmergeable = mergeable is not None and not mergeable

    # info from comments
    comments = pr.get_comments()
    last_comment = updated
    last_ping = updated
    user = get_github_user()
    reviewers = [ author ]
    for c in comments:
      if c['date'] > last_comment and c['author'] != user:
        last_comment = c['date']
      if c['date'] > last_ping and c['author'] == user:
        last_ping = c['date']
      reviewers.append(c['author'])
    reviewers = set(reviewers)

    # age info
    now = datetime.now()
    ping_age = (now - last_ping).total_seconds() / 3600 / 24
    comment_age = (now - last_comment).total_seconds() / 3600 / 24
    update_age = (now - updated).total_seconds() / 3600 / 24
    can_ping = ping_age > 3 or ping_age == update_age

    # pings
    if comment_age > Config.OLD_PR_DAYS and update_age > Config.OLD_PR_DAYS:
      #print("Very old PR ! : "+pr.url)
      pr.label(Config.PR_TOO_OLD_LABEL)
    # next steps
    #if comment_age > 5 and update_age > 5 and can_ping:
    #  print("forgotten pr @"+" @".join(reviewers))
    #if unmergeable and update_age > 1 and can_ping:
    #  print("Your pr is not mergeable anymore @"+author)
 

def pr_cleanup_all():
  for repo in Config.REPOSITORIES:
    print("Repo: " + repo)
    pr_cleanup(repo)


if __name__ == "__main__":
  arguments = docopt.docopt(__doc__)
  section = "quality-assistant"
  read_configuration(section)
  # qa specific configuration
  Config.WORKING_DIRECTORY = get_config("working_directory", "No 'working_directory' entry in " + Config.CONFIG_FILE, section)
  Config.LOGLEVEL = get_config("loglevel", "No 'loglevel' entry in " + Config.CONFIG_FILE, section) # verbose, info, error
  Config.LOCK_TIMEOUT = get_config("lock_timeout", None, section)
  Config.OLD_PR_DAYS = get_config("old_pr_days", None, section)
  if Config.OLD_PR_DAYS is None:
    Config.OLD_PR_DAYS = 30
    # use a value long enough to wait for a normal run (including tests) if don't use alt_dir
    # use a value that correspond to the overhead of cloning, checkouting and removing when using alt_dir
    Config.LOCK_TIMEOUT = 60

  if arguments['-d'] or arguments['--debug']:
    Config.LOGLEVEL = "debug"
  if arguments['--work-dir'] is not None:
    Config.WORKING_DIRECTORY = arguments['--work-dir']
  Config.force = arguments['-f'] or arguments['--force']
  if arguments['merge'] and arguments['all']:
    list_repositories()
    repo_merge_all(arguments['--alt-dir'], arguments['--job-id'])
  elif arguments['merge']:
    repo_merge(arguments['<repo>'], arguments['--alt-dir'], arguments['--job-id'])
  elif arguments['autolabel'] and arguments['all']:
    list_repositories()
    autolabel_all()
  elif arguments['autolabel']:
    autolabel(arguments['<repo>'])
  elif arguments['pr-cleanup'] and arguments['all']:
    list_repositories()
    pr_cleanup_all()
  elif arguments['pr-cleanup']:
    pr_cleanup(arguments['<repo>'])
     
